{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset"
      ],
      "metadata": {
        "id": "6lD7FGEKxWEU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usando como referencia a documentação de Ponto de Partida"
      ],
      "metadata": {
        "id": "jn0WG9Y_x4UU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install keras-tuner -q\n",
        "!kaggle datasets download -d arbazkhan971/cuhk-face-sketch-database-cufs --force\n",
        "!unzip -oq \"cuhk-face-sketch-database-cufs.zip\"\n",
        "!pip install pillow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8enI_l4gx_nz",
        "outputId": "98f5cb4a-7a08-409d-9c2a-f1c65ca79a29"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDataset URL: https://www.kaggle.com/datasets/arbazkhan971/cuhk-face-sketch-database-cufs\n",
            "License(s): copyright-authors\n",
            "Downloading cuhk-face-sketch-database-cufs.zip to /content\n",
            " 99% 112M/113M [00:04<00:00, 32.7MB/s]\n",
            "100% 113M/113M [00:04<00:00, 26.3MB/s]\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importando Bibliotecas"
      ],
      "metadata": {
        "id": "m5Yp66aWyYFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image as PILImage\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import f1_score,roc_curve,roc_auc_score\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from IPython.display import display, Image\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from tensorflow.keras import backend as K\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "kMkjon3rydVR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Funções"
      ],
      "metadata": {
        "id": "mfiyjGWH4xwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_files_in_folder(folder_path): #Retorna a lista com o nome dos arquivos na pasta.\n",
        "    try:\n",
        "      file_list = os.listdir(folder_path)\n",
        "      return file_list\n",
        "    except FileNotFoundError:\n",
        "      print(f\"Error: Folder not found at {folder_path}\")\n",
        "      return []\n",
        "\n",
        "def display_images_from_folder(folder_path): #exibe todas as imagens da pasta\n",
        "    image_files = list_files_in_folder(folder_path)\n",
        "    if not image_files:\n",
        "      print(f\"No images found in folder: {folder_path}\")\n",
        "      return\n",
        "\n",
        "    for image_file in image_files:\n",
        "      image_path = os.path.join(folder_path, image_file)\n",
        "      print(f\"Exibindo: {image_file}\")\n",
        "      display(Image(filename=image_path))\n",
        "\n",
        "def label_sex(folder_path): # Retorna uma lista de rótulos 0 ou 1 baseado\n",
        "                  # no nome do arquivo. Verifiquei todos os\n",
        "                  # arquivos para garantir que seguem esse padrão.\n",
        "      labels = []\n",
        "      image_files = list_files_in_folder(folder_path)\n",
        "      for file in image_files:\n",
        "          if file.lower().startswith('m'):\n",
        "            labels.append(0)\n",
        "          else:\n",
        "            labels.append(1)\n",
        "            return labels\n",
        "\n",
        "def norm_image(folder_path):\n",
        "        normalized_images = []\n",
        "        image_files = list_files_in_folder(folder_path)\n",
        "        for file in image_files:\n",
        "          image_path = os.path.join(folder_path, file)\n",
        "          image = PILImage.open(image_path)\n",
        "          image_array = np.array(image) / 255.0\n",
        "          normalized_images.append(image_array)\n",
        "        return normalized_images\n",
        "\n",
        "def graying_image(folder_path): #Função para criar a pasta que armazena as imagens em preto e branco.\n",
        "  input_folder = folder_path\n",
        "  output_folder = \"photos_gray\"\n",
        "  os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "  for file in list_files_in_folder(folder_path):\n",
        "    image_path = os.path.join(input_folder, file)\n",
        "    with PILImage.open(image_path) as image:\n",
        "      gray_image = image.convert(\"L\")\n",
        "      gray_image.save(os.path.join(output_folder, file))\n",
        "\n",
        "def best_hp(hp, color_scale=3, nome=\"TESTE\"):\n",
        "\n",
        "        model = models.Sequential(name=nome)\n",
        "        hp_filters = hp.Choice('filters', values=[31, 62, 129])\n",
        "        hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
        "        hp_activation = hp.Choice('activation', values=['relu', 'sigmoid', 'tanh', 'softmax'])\n",
        "\n",
        "        model.add(layers.Input(shape=(250, 200, color_scale)))\n",
        "\n",
        "        model.add(layers.Conv2D(hp_filters, (6, 6), activation=hp_activation, padding='same'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "        model.add(layers.Conv2D(hp_filters * 2, (5, 5), activation=hp_activation, padding='same'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "        model.add(layers.Conv2D(hp_filters * 3, (4, 4), activation=hp_activation, padding='same'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "        model.add(layers.Conv2D(hp_filters * 4, (3, 3), activation=hp_activation, padding='same'))\n",
        "        model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "        model.add(tf.keras.layers.Flatten())\n",
        "        model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "        optimizer_custom = Adam(learning_rate=hp_learning_rate)\n",
        "        model.compile(optimizer=optimizer_custom,\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "def top_melhores_cnn_da_residencia(color_scale,nome,hp_activation,hp_filters,lr):\n",
        "    model = models.Sequential(name=nome)\n",
        "    model.add(layers.Input(shape=(250, 200, color_scale)))\n",
        "\n",
        "    model.add(layers.Conv2D(hp_filters, (6, 6), activation=hp_activation, padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(hp_filters * 2, (5, 5), activation=hp_activation, padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(hp_filters * 3, (4, 4), activation=hp_activation, padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(layers.Conv2D(hp_filters * 4, (3, 3), activation=hp_activation, padding='same'))\n",
        "    model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "    model.add( tf.keras.layers.Flatten() )\n",
        "    model.add( tf.keras.layers.Dense(1, activation='sigmoid') )\n",
        "    optimizer_custom = Adam(learning_rate=lr)\n",
        "    model.compile(optimizer_custom,\n",
        "              loss=['binary_crossentropy'],\n",
        "              metrics=(['accuracy']))\n",
        "    return model"
      ],
      "metadata": {
        "id": "tfCWM1AH41LW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treinamento"
      ],
      "metadata": {
        "id": "lPUsFZFm_NEb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Chamar a pasta com as fotos"
      ],
      "metadata": {
        "id": "lDQ2u-xM_PZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "photos_folder = \"photos\"\n",
        "files_in_photos = list_files_in_folder(photos_folder)"
      ],
      "metadata": {
        "id": "pRnQauD0_WOh"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo com as imagens originais provenientes do dataset"
      ],
      "metadata": {
        "id": "z8OwyLl5_ZJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = label_sex(photos_folder)"
      ],
      "metadata": {
        "id": "Rdoq4s_Q-r6N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_images = norm_image(photos_folder)"
      ],
      "metadata": {
        "id": "-MLkkjqz-tvp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = normalized_images  #Array de imagens normalizadas.\n",
        "y = labels\n",
        "X = np.expand_dims(X, axis=-1)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.5, stratify=y, random_state=23)\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.4, stratify=y_temp, random_state=23)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "l3yEvdg7_o5y",
        "outputId": "001eae16-cc5f-4bb8-89da-c2e849437ec2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [188, 1]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-d607c48094f7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2780\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2782\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2784\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [188, 1]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    best_hp,\n",
        "    objective=kt.Objective(\"accuracy\", direction=\"max\"),\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='model_results_2',\n",
        "    project_name='grid_search'\n",
        ")"
      ],
      "metadata": {
        "id": "-galemmA_3dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "tuAOMkc__8i9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Melhores hiperparâmetros encontrados: {best_hps.values}\")"
      ],
      "metadata": {
        "id": "Jq2bKX46__f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation = 'relu'\n",
        "filters = 62\n",
        "lr = 0.01\n",
        "model = top_melhores_cnn_da_residencia(3,'M-1678',activation,filters,lr)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "wGSNPgavACtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "model.fit(X_train,\n",
        "          y_train,\n",
        "          batch_size=16,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping],)"
      ],
      "metadata": {
        "id": "mk5MWZ53AHNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('face_model.keras')"
      ],
      "metadata": {
        "id": "TNlXuozJAJwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
        "print(f\"Loss na validação: {val_loss}\")\n",
        "print(f\"Acurácia na validação: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "7szZ0xwtALh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_val)\n",
        "pred_labels = (pred > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "J_sNOcRaANvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_val, pred_labels)\n",
        "print(f\"AUC-ROC: {auc}\")\n",
        "f1 = f1_score(y_val, pred_labels)\n",
        "print(f\"F1-Score: {f1}\")\n",
        "fpr, tpr, thresholds = roc_curve(y_val, pred_labels)\n",
        "\n",
        "# Plotando a curva ROC\n",
        "plt.plot(fpr, tpr, marker='.', label='Modelo')\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "  if(y_val[i] !=pred_labels[i][0]):#Analisando as fotos em que o modelo errou a\n",
        "                                   #previsão\n",
        "      plt.imshow(X_val[i].reshape(250, 200,3), cmap=None)\n",
        "      plt.title(f\"Verdadeiro: {y_val[i]} | Previsto: {pred_labels[i][0]}\")\n",
        "      plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "nEx7pH3zAPTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo com imagens convertidas para preto e branco"
      ],
      "metadata": {
        "id": "u_jL_xoEAXDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para criar uma rede capaz de diferenciar rostos masculinos de femininos, transformamos todas as imagens para preto e branco, pois a cor não é um fator determinante para essa característica. No entanto, também treinamos o modelo com as imagens originais para verificar se há alguma melhora no desempenho."
      ],
      "metadata": {
        "id": "UapmYCEjAfEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graying_image(photos_folder)\n",
        "photos_gray_folder = \"photos_gray\""
      ],
      "metadata": {
        "id": "yLwJrwZ5AqtD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_images_from_folder(photos_gray_folder)"
      ],
      "metadata": {
        "id": "bjBzHB0dArWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = label_sex(photos_gray_folder)"
      ],
      "metadata": {
        "id": "Jp4tzebkAtJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Quantidade de 0s: {labels.count(0)}\")\n",
        "print(f\"Quantidade de 1s: {labels.count(1)}\")"
      ],
      "metadata": {
        "id": "6HJI_KVkA0wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_gray_images = norm_image(photos_gray_folder)"
      ],
      "metadata": {
        "id": "1ndSjFTgA4Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = normalized_gray_images\n",
        "y = labels\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.5, stratify=y, random_state=23)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.4, stratify=y_temp, random_state=23)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "QUSduu0DA44R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gray = top_melhores_cnn_da_residencia(1,'G-0909',activation,filters,lr)\n",
        "model_gray.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "X0xOzGUVBBz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',   # Métrica a ser monitorada\n",
        "    patience=5,           # Número de épocas sem melhoria antes de parar\n",
        "    restore_best_weights=True  # Restaura os pesos da melhor época\n",
        ")\n",
        "model_gray.fit(X_train,\n",
        "          y_train,\n",
        "          batch_size=16,\n",
        "          epochs=20,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "SB-tnTreBFap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_gray.save('gray_face_model.keras')"
      ],
      "metadata": {
        "id": "ZirPerc9BH0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy_gray = model_gray.evaluate(X_val, y_val, verbose=1)\n",
        "print(f\"Loss na validação: {val_loss}\")\n",
        "print(f\"Acurácia na validação: {val_accuracy_gray}\")"
      ],
      "metadata": {
        "id": "jlW5RxTNBImq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_gray.predict(X_val)\n",
        "pred_labels = (pred > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "j67HeYLWBLOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_val, pred_labels)\n",
        "print(f\"AUC-ROC: {auc}\")\n",
        "f1 = f1_score(y_val, pred_labels)\n",
        "print(f\"F1-Score: {f1}\")\n",
        "fpr, tpr, thresholds = roc_curve(y_val, pred_labels)\n",
        "\n",
        "plt.plot(fpr, tpr, marker='.', label='Modelo')\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "  if(y_val[i] != pred_labels[i][0]):\n",
        "      plt.imshow(X_val[i].reshape(250, 200,1), cmap=\"gray\")\n",
        "      plt.title(f\"Verdadeiro: {y_val[i]} | Previsto: {pred_labels[i][0]}\")\n",
        "      plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "CfNFRyybBMw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelo com data augmentation"
      ],
      "metadata": {
        "id": "XDr9MECNBR2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = label_sex(photos_folder)"
      ],
      "metadata": {
        "id": "zSjBurjvBUmQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_images = norm_image(photos_folder)"
      ],
      "metadata": {
        "id": "HyNAOsgFBVRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = normalized_images\n",
        "y = labels\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.5, stratify=y, random_state=23)\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.4, stratify=y_temp, random_state=23)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "metadata": {
        "id": "MA8CzRApBYr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        ")\n",
        "train_generator = datagen.flow(\n",
        "    X_train, y_train, batch_size=16\n",
        ")"
      ],
      "metadata": {
        "id": "UGoNOq4VBd70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    best_hp,\n",
        "    objective=kt.Objective(\"accuracy\", direction=\"max\"),\n",
        "    max_epochs=20,\n",
        "    factor=3,\n",
        "    directory='model_results_3',\n",
        "    project_name='grid_search_data_ag'\n",
        ")"
      ],
      "metadata": {
        "id": "lVSfKBtOBfeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_generator, epochs=20, validation_data=(X_test, y_test))"
      ],
      "metadata": {
        "id": "5mn9lTdXBis_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(f\"Melhores hiperparâmetros encontrados: {best_hps.values}\")"
      ],
      "metadata": {
        "id": "BPbMve6ABkbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activation = 'relu'\n",
        "filters = 31\n",
        "lr = 0.001\n",
        "model = top_melhores_cnn_da_residencia(3,'DA-1882',activation,filters,lr)\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pnmBlLCeBlGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='loss',   # Métrica a ser monitorada\n",
        "    patience=9,           # Número de épocas sem melhoria antes de parar\n",
        "    restore_best_weights=True  # Restaura os pesos da melhor época\n",
        ")"
      ],
      "metadata": {
        "id": "6WWIZpxMBqEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_generator,#usar searchgrig hyperopt\n",
        "          batch_size=16,\n",
        "          epochs=50,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "J6MePgy1BtEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('face_model.keras')"
      ],
      "metadata": {
        "id": "DrktBQO_BuzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_loss, val_accuracy= model.evaluate(X_val, y_val, verbose=1)\n",
        "print(f\"Loss na validação: {val_loss}\")\n",
        "print(f\"Acurácia na validação: {val_accuracy_data_ag}\")"
      ],
      "metadata": {
        "id": "BBPn8p9SBwJ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(X_val)\n",
        "pred_labels = (pred > 0.5).astype(int)"
      ],
      "metadata": {
        "id": "OGOw6uSFBxdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auc = roc_auc_score(y_val, pred_labels)\n",
        "print(f\"AUC-ROC: {auc}\")\n",
        "f1 = f1_score(y_val, pred_labels)\n",
        "print(f\"F1-Score: {f1}\")\n",
        "fpr, tpr, thresholds = roc_curve(y_val, pred_labels)\n",
        "\n",
        "plt.plot(fpr, tpr, marker='.', label='Modelo')\n",
        "plt.xlabel('Taxa de Falsos Positivos (FPR)')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos (TPR)')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "for i in range(len(X_val)):\n",
        "  if(y_val[i] !=pred_labels[i][0]):\n",
        "      plt.imshow(X_val[i].reshape(250, 200,3), cmap=None)\n",
        "      plt.title(f\"Verdadeiro: {y_val[i]} | Previsto: {pred_labels[i][0]}\")\n",
        "      plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "BQQ9ECbUBze3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}